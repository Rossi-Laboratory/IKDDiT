<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="description" content="IKDDiT: Implicit Knowledge Distillation Diffusion Transformer for Photolithography Overlay Map Generation">
  <title>Photolithography Overlay Map Generation with Implicit Knowledge Distillation Diffusion Transformer</title>
  <style>
    :root {
      --ink: #0f172a;
      --muted: #475569;
      --brand: #1a237e;
      --line: #e2e8f0;
      --bg: #ffffff;
      --card: #f8fafc;
    }
    * { box-sizing: border-box; }
    body {
      font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, 'Helvetica Neue', Arial, 'Noto Sans', 'Apple Color Emoji', 'Segoe UI Emoji';
      margin: 0; background: var(--bg); color: var(--ink); line-height: 1.65;
    }
    a { color: var(--brand); text-decoration: none; }
    header {
      padding: 3rem 1rem; border-bottom: 1px solid var(--line); text-align: center;
      background: linear-gradient(180deg, #eef2ff 0%, #ffffff 60%);
    }
    header h1 { margin: 0 0 .5rem; font-size: clamp(1.6rem, 2.5vw, 2.25rem); }
    header p, header div { margin: 0; color: var(--muted); }
    main { max-width: 1080px; margin: 0 auto; padding: 2rem 1rem 4rem; }
    nav.toc { background: #f5f7ff; border: 1px solid #dfe3ff; border-radius: 10px; padding: 1rem 1.25rem; margin-bottom: 2rem; }
    nav.toc ul { margin: .25rem 0 0; padding-left: 1.1rem; }
    section { margin: 2.25rem 0; }
    h2 {
      color: var(--brand); margin: 0 0 .75rem; padding-left: .5rem; border-left: 4px solid var(--brand);
      font-size: clamp(1.25rem, 2vw, 1.5rem);
    }
    .muted { color: var(--muted); font-size: .95rem; }
    .card { background: var(--card); border: 1px solid var(--line); border-radius: 12px; padding: 1rem 1.25rem; }
    .grid { display: grid; grid-template-columns: 1fr; gap: 1.25rem; }
    @media (min-width: 900px) { .grid.two { grid-template-columns: 1fr 1fr; } }
    figure { margin: 0; }
    figure img { width: 100%; border: 1px solid var(--line); display: block; }
    figcaption { font-size: .95rem; color: var(--muted); margin-top: .5rem; }
    .figblock { border: 1px solid var(--line); border-radius: 10px; background: #fff; overflow: hidden; }
    .figdesc { padding: .8rem 1rem; font-weight: 600; background: #f8fafc; border-bottom: 1px solid var(--line); }
    .figwrap { padding: 1rem; }
    .core-figure img { width: 100%; max-width: 1080px; margin: 0 auto; display: block; border: 1px solid var(--line); box-shadow: 0 6px 24px rgba(16,24,40,.08); }
    pre { background: #0b1020; color: #f8f8f2; padding: 1rem; border-radius: 8px; overflow: auto; }
    footer { border-top: 1px solid var(--line); padding: 1rem; text-align: center; color: var(--muted); }
    .meta { display: flex; gap: .75rem; flex-wrap: wrap; font-size: .95rem; color: var(--muted); }
    .meta span { background: #eef2ff; border: 1px solid #dfe3ff; border-radius: 999px; padding: .25rem .6rem; }
  </style>
</head>
<body>
  <header>
    <h1>Photolithography Overlay Map Generation with Implicit Knowledge Distillation Diffusion Transformer</h1>
    <div style="margin-top:1rem; font-size:1.05rem; line-height:1.6;">
      <div style="display:flex; justify-content:center; gap:3rem; flex-wrap:wrap;">
        <span><strong>Yuan-Fu Yang<sup>1</sup></strong></span>
        <span><strong>Hsiu-Hui Hsiao<sup>2</sup></strong></span>
      </div>
      <div style="margin-top:.5rem; font-style:italic;">
        <sup>1</sup>National Yang Ming Chiao Tung University,&nbsp;
        <sup>2</sup>National Taiwan University of Science and Technology
      </div>
      <div style="margin-top:0.75rem; font-size:1rem;">
        <a href="#">Paper</a> |
        <a href="#">Project Page</a> |
        <a href="#">Video</a> |
        <a href="https://github.com/Rossi-Laboratory/IKDDiT" target="_blank">Code</a>
      </div>
    </div>
  </header>

  <main>
    <section class="meta">
      <span>Diffusion Transformer</span>
      <span>Photolithography</span>
      <span>Overlay Map Generation</span>
      <span>Semiconductor Manufacturing</span>
    </section>

    <nav class="toc">
      <strong>Contents</strong>
      <ul>
        <li><a href="#intro">Introduction</a></li>
        <li><a href="#core">Core Idea</a></li>
        <li><a href="#Training">Training Efficiency</a></li>
        <li><a href="#results">Results</a></li>
        <li><a href="#resources">Resources</a></li>
        <li><a href="#bibtex">BibTeX</a></li>
      </ul>
    </nav>

    <section id="intro">
      <h2>Introduction</h2>
      <div class="card">
        <p>
          IKDDiT explores how diffusion models and knowledge distillation can improve overlay map generation
          in semiconductor photolithography. This page provides an accessible overview of the motivation,
          the core design, and representative results, with figures consolidated from the paper and
          its supplementary material.
        </p>
        <figure class="core-figure" style="margin-top:1rem; text-align:center;">
          <img src="https://i.ibb.co/XfDLmbt0/1.png" alt="High-level overview of IKDDiT pipeline" style="width:70%; height:auto;">
        </figure>

      </div>
    </section>

    <section id="core">
      <h2>Core Idea</h2>
      <div class="card">
        <p>
          Rather than relying on a heavy standalone model, IKDDiT uses a distilled teacher network to inject
          semiconductor-specific priors into a compact diffusion generator. The result is a model that is
          both efficient and accurate for overlay map synthesis.
        </p>
        <figcaption>
          Architecture of the IKDDiT, which leverages a pre-trained text encoder
          ε<sub>φ<sub>t</sub></sub> and an image encoder ε<sub>φ<sub>i</sub></sub>,
          developed through unified contrastive learning, to generate conditional tokens.
          These tokens are subsequently processed by the teacher and student DiT encoders
          to perform a self-supervised discriminative process using D<sub>φ</sub>
          within the joint embedding space.
        </figcaption>
        <p class="muted">
          In short: a compact diffusion model enhanced by knowledge transfer for manufacturing data.
        </p>
        <figure class="core-figure" style="margin-top:1rem; text-align:center;">
          <img src="https://i.ibb.co/3yGWV453/2.png" alt="IKDDiT" style="width:70%; height:auto;">
        </figure>
      </div>
    </section>
    <section id="Training">
      <h2>Training efficiency</h2>
      <div class="card">
        <p>
          To evaluate the convergence behavior of our IKDDiT model, we compare FID scores across 
          training stages against state-of-the-art baselines. All models, in the XL configuration,
          are trained with a batch size of 64 for up to 578.1k iterations. As shown in Figure 5, 
          IKDDiT exhibits consistently faster convergence. At 250k iterations, IKDDiT reaches an 
          FID of 11.6, already surpassing DiT, MDT, and MaskDiT, which only achieve FID scores of 
          14.1, 12.2, and 11.9, respectively, after 500k iterations. Furthermore, IKDDiT attains 
          an FID of 6.8 at 500k iterations, outperforming all competing methods. These results 
          demonstrate that IKDDiT converges nearly twice as fast, underscoring the effectiveness 
          of incorporating self-supervised discrimination into DiT training.
        </p>
        <figure class="core-figure" style="margin-top:1rem; text-align:center;">
          <img src="https://i.ibb.co/zTMTtHxd/3.png" alt="Training" style="width:50%; height:auto;">
        </figure>
      </div>
    </section>
    
    <section id="results">
      <h2>Results</h2>
    
      <div class="grid two">
        <!-- Figure 2 -->
        <div class="figblock">
          <div class="figdesc">Scalability.</div>
          <div class="figwrap">
            <img src="https://i.ibb.co/WmCgpLz/4.png" alt="Figure 4" style="width:100%; height:auto;">
          </div>
        </div>
    
        <!-- Figure 3 -->
        <div class="figblock">
          <div class="figdesc">Model Scaling on Training Loss.</div>
          <div class="figwrap">
            <img src="https://i.ibb.co/99SKpXS1/5.png" alt="Figure 5" style="width:100%; height:auto;">
          </div>
        </div>
      </div>
    </section>

    <section id="resources">
      <h2>Resources</h2>
      <div class="card">
        <p>
          <a href="https://drive.google.com/uc?export=download&id=1oL0YITGL6YDhyEBgj8YMXhXFlUCnANIG" target="_blank">Main Paper</a> ·
          <a href="https://drive.google.com/uc?export=download&id=13wuvgJa7udT2kTCPNtFrPjX_qLM_sMuZ" target="_blank">Supplementary</a>
        </p>
      </div>
    </section>

    <section id="bibtex">
      <h2>BibTeX</h2>
      <div class="card">
<pre>@inproceedings{IKDDiT2025,
  author    = {Chen, Zhen-Qi and Yang, Yuan-Fu},
  title     = {IKDDiT: Implicit Knowledge Distillation Diffusion Transformer for Photolithography Overlay Map Generation},
  booktitle = {Proceedings of ...},
  year      = {2025},
  note      = {Project page}
}</pre>
        <p class="muted">Replace with the official venue and full bibliographic information once finalized.</p>
      </div>
    </section>
  </main>

  <footer>
    <p>&copy; 2025 IKDDiT Project. All rights reserved.</p>
  </footer>
</body>
</html>
